---
title: '生成式模型发展历程：从概率游戏到 AI 造物主的进化史'
date: 2024-09-30
permalink: /posts/2024/09/generative-models-evolution/
tags:
  - 深度学习
  - 生成式模型
  - GAN
  - 扩散模型
  - 人工智能
---

![生成式模型进化时间线](https://p3-flow-imagex-sign.byteimg.com/ocean-cloud-tos/image_skill/9db4a44e-cd05-4424-a37f-ae13da9aeff2_1748101643829671353~tplv-a9rns2rl98-web-watermark-v2.png?rk3s=b14c611d&x-expires=1779637643&x-signature=TmobFSKIwNUDSTgyXYp580JFyZY%3D)

一、史前时代：当数学公式开始「空想」



在深度学习统治世界之前，生成式模型的祖先们还在概率的海洋里扑腾。


### 1.1 概率模型的「看图说话」&#xA;

1980 年代的研究者们发现，想让机器生成数据，本质是求解一个「逆向工程」问题：**如何用数学公式描述真实数据的分布规律？**

于是他们搬出了概率论的终极武器 ——**联合概率分布**：


$P(x) = \sum_z P(x|z)P(z)$

这里的 $  z  $ 是隐藏的「脑洞变量」，比如想生成一张猫的图片，$  z  $ 可能代表「猫的颜色」「耳朵大小」「尾巴长度」等参数。


#### 代表模型：隐马尔可夫模型（HMM）&#xA;

这货在语音识别和自然语言处理里火过一阵子，原理类似「接龙游戏」：根据前一个状态预测下一个状态。但缺点很明显：太「死板」，生成的样本像流水线产品，比如生成句子时经常出现语法正确但语义诡异的「人工智障文学」。


### 1.2 能量模型的「玄学占卜」&#xA;

1990 年代，学者们从物理世界获得灵感：真实数据应该像稳定的「能量最低点」。于是提出**能量函数** $  E(x)  $，认为数据分布符合：


$P(x) = \frac{\exp(-E(x))}{Z}$

其中 $  Z  $ 是归一化常数，可惜这东西太难算，堪比「计算宇宙的熵」，导致能量模型长期停留在理论阶段。


二、深度学习觉醒：当神经网络开始「脑补」



2010 年后，深度学习带着「暴力美学」撕开了生成式模型的新篇章。


### 2.1 对抗的艺术：GAN 的「互撕哲学」&#xA;

2014 年，Goodfellow 带着他的「对抗生成网络（GAN）」掀起了一场「AI 内战」。




*   **生成器（G）**：负责造假，目标是骗过判别器


*   **判别器（D）**：负责打假，目标是区分真实数据和生成数据


两者的对抗过程可以用一个「相爱相杀」的公式表示：


$\min_G \max_D \mathbb{E}_{x\sim p_{data}}[\log D(x)] + \mathbb{E}_{z\sim p_z}[\log(1-D(G(z)))]$

打个比方：生成器是「野鸡画家」，判别器是「毒舌评论家」。一开始画家画得像一坨马赛克，评论家一眼识破；随着不断互撕，画家越来越会「骗」，评论家越来越会「挑刺」，最终达到「以假乱真」的平衡。


#### 名场面：英伟达用 GAN 生成以假乱真的人脸&#xA;



![GAN生成的虚拟人脸](https://p3-search.byteimg.com/obj/pgc-image/6f4d4f189e1744c287df56a8066f113a)

但 GAN 有个「暴脾气」：训练不稳定，容易出现「模式崩溃」（只会生成几种固定样本），就像画家只会画一种风格的画，被评论家骂到怀疑人生。


### 2.2 温柔的「自编码器」：VAE 的「数据压缩术」&#xA;

同年（2014 年），另一个「佛系模型」变分自编码器（VAE）诞生了。它的核心思想是：先把数据压缩成「特征密码」（编码过程），再用密码还原数据（解码过程）。通过最大化 \*\* 证据下界（ELBO）\*\* 保证还原质量：


$\log P(x) \geq \mathbb{E}_{q(z|x)}[\log P(x|z)] - D_{KL}(q(z|x) || P(z))$

简单说，VAE 像一个「数据打包员」，把复杂的数据压缩成小文件，需要时再解压。生成的样本虽然没 GAN 那么逼真，但胜在「稳定输出」，适合做图像插值（比如让猫逐渐变成狗）。


#### 趣味应用：用 VAE 生成「不存在的水果」&#xA;



![VAE生成的奇幻水果](https://p3-search.byteimg.com/obj/labis/ba4b78eaa0037707ef375181f1310733)

三、Transformer 统治世界：从「文字接龙」到「万物生成」



2017 年，谷歌提出的 Transformer 架构，让生成式模型从「单模态玩家」进化成「全能选手」。


### 3.1 语言模型的「脑洞大开」&#xA;

GPT 系列（从 GPT-1 到 GPT-4）用 Transformer 实现了「史上最强文字接龙」：




*   通过分析海量文本，学会人类语言的「套路」


*   输入一句话，能生成逻辑连贯的长文本，甚至写小说、代码、诗歌


核心原理是**自注意力机制**：


$\text{Attention}(Q,K,V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$

相当于让模型在生成每个词时，「回头看看」前面的词，确保前后逻辑一致。


#### 名场面：GPT-3 写出《纽约客》级别的散文&#xA;



```
在数字的迷雾中，Transformer的神经元编织着语言的经纬。每个Token都是一颗星，在注意力的银河里相互辉映，最终汇聚成人类文明的镜像。
```

*（是的，这句话就是 AI 写的）*

### 3.2 多模态生成：让 AI「眼脑手」并用&#xA;

当图像 Transformer（如 ViT）遇到语言模型，神奇的事情发生了：




*   **DALL-E**：输入文字描述，生成对应图像（比如「一只戴着墨镜的企鹅在跳探戈」）


*   **MidJourney**：用艺术风格关键词，生成堪比大师级的画作


*   **Stable Diffusion**：开源后让普通人也能「一键生成壁纸」


背后的技术秘密是「跨模态对齐」：让文字和图像的特征在同一个「语义空间」对话，就像给 AI 装上「双语翻译器」。


四、最新浪潮：扩散模型的「洗照片哲学」与大模型觉醒



2020 年爆发的扩散模型（Diffusion Model），被称为「生成式模型的集大成者」。


### 4.1 逆向扩散：从「高斯噪声」到「高清大片」&#xA;

扩散模型的思路像「洗照片的逆过程」：




1.  **正向扩散**：给真实图像逐渐添加高斯噪声，直到变成纯噪声（比如把猫图变成马赛克）


2.  **逆向扩散**：从纯噪声开始，一步步去噪还原成清晰图像


数学上可以表示为求解**去噪分数匹配**问题：


$\epsilon_\theta(x_t, t) \approx -\nabla_{x_t} \log p(x_{t-1}|x_t)$

虽然计算复杂度比 GAN 高（需要迭代几十到几百次），但生成质量碾压前者，尤其是在细节处理上（比如生成带手的人像，GAN 经常画成「五根香肠」，扩散模型能画出精致的手指）。


#### 视觉震撼：Stable Diffusion 生成的超现实场景&#xA;



![扩散模型生成的蒸汽朋克城市](https://p9-flow-imagex-sign.byteimg.com/ocean-cloud-tos/image_skill/d26a1b36-0479-4086-a24e-b22dfdc7fbae_1748101762945571625~tplv-a9rns2rl98-web-watermark-v2.png?rk3s=b14c611d&x-expires=1779637762&x-signature=756NdbZpnaMwT3BoL1zzLmWD5P0%3D)

### 4.2 大模型时代：当生成式模型「学会学习」&#xA;

2023 年以来，随着 GPT-4、MidJourney v6 等模型的发布，生成式模型进入「通用人工智能」前夜：




*   **多模态交互**：能同时处理文字、图像、语音、视频


*   **上下文理解**：支持超长文本（比如 GPT-4 能处理 3.2 万字的输入）


*   **逻辑推理**：不仅能生成，还能理解因果关系（比如回答「如果猫会说话，世界会怎样？」）


五、未来展望：当 AI 成为「数字造物主」



**每个生成式 AI 都是一个平行宇宙。** 当你在 MidJourney 输入 “科比在寺庙扫地”，AI 会生成一个穿着僧袍、手持扫帚的篮球巨星，尽管脚掌比例诡异、动作略显笨拙，却构建了一个与现实平行的叙事空间。这个空间里，逝者可以 “复活”，富豪可以沦为平民，甚至柏拉图能坐在大理石座椅上敲代码 —— 每个 AI 模型都是一扇任意门，通向由算法、数据和人类想象共同编织的异世界。


比如 Stable Diffusion 创造的超现实城市，每扇窗户里都藏着 AI 杜撰的故事；GPT-4 撰写的《纽约客》散文，用 Transformer 神经元编织着数字文明的镜像。这些模型如同不同的 “宇宙大爆炸”，DALL-E 以文本为奇点，炸开视觉创意的星云；VAE 用数据压缩术，在隐空间中折叠出无数种可能的 “水果”。更妙的是，当你在 AI 绘画工具中输入 “蒸汽朋克风格的长城”，它不仅生成图像，更创造了一个机械齿轮与青砖灰瓦共生的文明体系 —— 这就是生成式 AI 的魅力：**它不是在模仿现实，而是在创造无数个自洽的虚拟现实**。


现在的生成式模型已经能：




*   写小说、谱曲、设计游戏场景


*   生成逼真的 3D 模型、视频动画


*   甚至辅助科研（比如设计新药物分子结构）


但挑战依然存在：




*   **伦理问题**：如何防止 AI 生成虚假信息（深度伪造）？


*   **能耗问题**：训练大模型需要消耗相当于「一座小城市」的电量


*   **理解边界**：AI 生成的内容，真的理解背后的意义吗？


不过正如《连线》杂志说的：


> "生成式模型不是终点，而是人类与 AI 共创未来的起点。"
>

下次当你看到一张「不存在的风景照」、读到一篇「AI 写的短篇小说」，不妨想想：这可能是人类文明与硅基智能的一次「跨物种协作」。


生成式模型的故事还在继续，下一个颠覆可能就在明天，而我们，正在见证 AI 从「模仿者」到「创作者」的华丽转身。
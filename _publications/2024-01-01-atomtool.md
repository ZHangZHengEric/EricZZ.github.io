---
title: "AtomTool: Empowering Large Language Models with Tool Utilization Skills"
collection: publications
category: conferences
permalink: /publication/2024-01-01-atomtool
excerpt: 'Enhancing LLMs with tool utilization capabilities | 增强大语言模型的工具使用能力'
date: 2024
venue: 'The 7th Chinese Conference on Pattern Recognition and Computer Vision (PRCV 2024) | 第七届中国模式识别与计算机视觉大会'
paperurl: 'https://link.springer.com/content/pdf/10.1007/978-981-97-8487-5_23.pdf'
citation: 'Yongle Li, Zheng Zhang, Junqi Zhang, Wenbo Hu, Yongyu Wu, Richang Hong. (2024). "AtomTool: Empowering Large Language Models with Tool Utilization Skills" <i>PRCV 2024</i>.'
---

本文提出了AtomTool框架，旨在解决大语言模型在工具使用方面的挑战。研究重点包括：
- 探索中文大语言模型在工具使用上的零样本泛化能力
- 开发包含16,000条中文条目的工具使用数据集
- 分析提示词设计和工具数量对模型性能的影响
- 在中文环境下验证框架有效性

This paper introduces AtomTool framework addressing challenges in LLM tool utilization. Key aspects include:
- Investigating zero-shot generalization of Chinese LLMs in tool usage
- Developing a 16,000-entry Chinese tool utilization dataset
- Analyzing prompt design and tool quantity effects on performance
- Validating framework effectiveness in Chinese context

实验结果表明，AtomTool在多数情况下优于ChatGPT等闭源模型在零样本泛化上的表现。研究为中文大语言模型的工具获取能力发展奠定了基础。

Experimental results show AtomTool outperforms closed-source models like ChatGPT in zero-shot generalization in most cases. This work establishes foundations for advancing tool acquisition in Chinese LLMs.
